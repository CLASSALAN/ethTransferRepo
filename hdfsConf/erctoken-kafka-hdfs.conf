# 定义source，channel和sink组件
a6.sources = r1
a6.channels = c1
a6.sinks = k1

# 配置source参数，使用KafkaSource
a6.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a6.sources.r1.batchSize = 5000
a6.sources.r1.batchDurationMillis = 2000
a6.sources.r1.kafka.bootstrap.servers = skydp-server-4:9092,skydp-server-5:9092,skydp-server-6:9092
a6.sources.r1.kafka.topics = erc_token_data
a6.sources.r1.kafka.consumer.group.id = eth_group

# 使用memory channel传输数据
a6.channels.c1.type = file
a6.channels.c1.checkpointDir = /opt/script/flume/checkpoint/erc_token_data
a6.channels.c1.dataDirs = /opt/script/flume/data/erc_token_data

# 配置sink参数，将数据导入HDFS
a6.sinks.k1.type = hdfs
a6.sinks.k1.hdfs.path = /user/upload/eth_json/erc_token_data/%Y-%m-%d
a6.sinks.k1.hdfs.filePrefix = erc_token_data
a6.sinks.k1.hdfs.round = false

#a6.sinks.k1.hdfs.callTimeout=1900000

# 文件回滚参数
a6.sinks.k1.hdfs.rollInterval = 1800
a6.sinks.k1.hdfs.rollSize = 256000000
a6.sinks.k1.hdfs.rollCount = 0

# 使用lzo压缩
a6.sinks.k1.hdfs.fileType = CompressedStream
a6.sinks.k1.hdfs.codeC = lzop

# 连接各组件
a6.sources.r1.channels = c1
a6.sinks.k1.channel= c1
