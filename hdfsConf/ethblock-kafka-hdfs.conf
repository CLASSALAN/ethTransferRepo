# 定义source，channel和sink组件
a4.sources = r1
a4.channels = c1
a4.sinks = k1

# 配置source参数，使用KafkaSource
a4.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a4.sources.r1.batchSize = 5000
a4.sources.r1.batchDurationMillis = 2000
a4.sources.r1.kafka.bootstrap.servers = skydp-server-4:9092,skydp-server-5:9092,skydp-server-6:9092
a4.sources.r1.kafka.topics = eth_block_data
a4.sources.r1.kafka.consumer.group.id = eth_group

# 使用memory channel传输数据
a4.channels.c1.type = file
a4.channels.c1.checkpointDir = /opt/script/flume/checkpoint/eth_block_data
a4.channels.c1.dataDirs = /opt/script/flume/data/eth_block_data

# 配置sink参数，将数据导入HDFS
a4.sinks.k1.type = hdfs
a4.sinks.k1.hdfs.path = /user/upload/eth_json/eth_block_data/%Y-%m-%d
a4.sinks.k1.hdfs.filePrefix = eth_block_data
a4.sinks.k1.hdfs.round = false

#a4.sinks.k1.hdfs.callTimeout=1900000

# 文件回滚参数
a4.sinks.k1.hdfs.rollInterval = 1800
a4.sinks.k1.hdfs.rollSize = 256000000
a4.sinks.k1.hdfs.rollCount = 0

# 使用lzo压缩
# a4.sinks.k1.hdfs.fileType = CompressedStream
# a4.sinks.k1.hdfs.codeC = lzop

# 连接各组件
a4.sources.r1.channels = c1
a4.sinks.k1.channel= c1
